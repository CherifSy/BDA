---
layout: post
title: Advanced Feature Construction through PCA, LDA, and Kernel Methods

---
## Project Proposal

### Team Members
* Adam Johnson - Computer Science (GTID:902755794   gt Email:ajohnson89@gatech.edu)
* Mahdi Roozbahani - Computational Science and Engineering (GTID:902973169   gt Email:mahdir@gatech.edu)

### PROJECT DESCRIPTION


#### PCA

Principal Component Analysis is a famous method to reduce the dimensions of data into the most efficient dimensions. Later on, we will use the low dimensional representation of our data to apply classification methods. In order to apply this method, we need to obtain eigen-vectors and eigen-values of our data. This process might decrease the computational time of training the data by employing a lower representation of the data. 

#### LDA

Linear Discriminant Analysis is a dimensionality reduction method for supervised machine learning. This method might provide more accurate classificataion results as our current problem is supervised machine learning. This method will map the data into new dimensions where the same famility clusters will be as close as possible to each other, on the same time, it will highly distinguished between different family clusters. We are expecting to acquire more accurate results together with high computational speed in terms of training the data. 

#### Kernel Methods

We are going to use Kernel trick to transfer data-set into a higher dimensions.  For example Radial basis function kernel or Polynomial kernelData may be linearly separable in the higher dimensions, and we could classify our data as accurate as possible. This approach might provide us more accurate classification results. 

<p align="center">
<iframe src="https://www.flickr.com/photos/127802705@N04/16264156877/player/" width="1024" height="410" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen oallowfullscreen msallowfullscreen></iframe>
</p>
<p align="center">
 Data might be linearly separable in higher dimensions
</p>


### DATA SET
(describe the dataset you are going to use, how you will use the dataset? raw format, or some standard format?)
We are going to employ CMS data into our predictive modeling. We will join all the features in Benificiary-Summary, In-patient claims_Sample,Out-patient claims_Sample, and Prescription-Drug_Events_Sample in one file including all the features. Afterwards, the predetice modeling and proposed approached will be applied on samples having all the features.

### ENVIRONMENT

We plan on using the AWS platform to utilize Hadoop as well as Pig and/or Hive.
See Help Needed below.

### EVALUATION CRITERIA
In the chosen model to predict the classification of our data, we can compare the result of the raw data which are not being transformed in any new dimensions to the results of data transformed into the new dimensions based on the PCA, LDA, or Kernel approach. 

### HELP NEEDED (OPTIONAL)

We are unsure of what environment criteria would best fit our project objectives. A quick meeting with Dr. Sun or one of the TAs should remedy this problem.


#### References

* [Eric Kim. Everything You Wanted to Know about the Kernel Trick.](http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html)
* [PÃ©rez-Cruz, Fernando, and Olivier Bousquet. "Kernel methods and their potential use in signal processing." Signal Processing Magazine, IEEE 21.3 (2004): 57-65.](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1296543&tag=1)
* [Sondhi, Parikshit. "Feature Construction Methods: A Survey." sifaka. cs. uiuc. edu (2009).](http://sifaka.cs.uiuc.edu/~sondhi1/survey3.pdf)
